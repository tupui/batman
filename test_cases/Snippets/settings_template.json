{
    #
    # PARAMETERS FOR SPACE
    #
    "space": {
        # Lower and upper end points (corners) that define a portion of space.
        # format: list(2-lists) of [min] an [max] coordinates.
        "corners": [[1.0, 1.0], [3.1415, 3.1415]],
        "sampling": {
            # Maximum number of point used: initial sampling + resampling
            # format: integer
            "init_size": 10,
            # Method used to generate the points
            # format: one of 'uniform', 'halton', 'sobol', 'lhsc', 'lhsr',
            # "sobolscramble", "faure"
            "method": "halton",
        },
        # Points provider
        # Could be a list of points or a dictionary with sampling parameters
        "resampling": {
            # Innerspace defined by corners for resampling
            # format: float
            "delta_space": 0.08,
            # Number of points for initial sampling
            # format: integer
            "resamp_size": 6,
            # Resampling strategy: None, 'sigma', 'loo_sigma', 'loo_sobol",
            # "extrema", "hybrid"
            "method": "sigma",
            # Optional, only for combining methods
            "hybrid": [["sigma", 4], ["loo_sobol", 2]],
            # Stopping criterion for automatic resampling
            # format: float
            "q2_criteria": 0.8
        }
    },
    #
    # PARAMETERS FOR POD
    #
    "pod": {
        # Maximum number of modes to be kept
        # format: integer
        "dim_max": 100,
        # Tolerance of the modes to be kept.
        # A percentage of the sum of the singular values, values that account for less than this tolerance are ignored.
        # format: float
        "tolerance": 0.99,
        # Type of pod to perform.
        # format: one of 'static', 'dynamic'
        "type": "static"
    },
    #
    # PARAMETERS FOR SNAPSHOTS
    #
    "snapshot": {
        # Maximum number of simultaneous running snapshot provider
        # format: integer > 0
        "max_workers": 10,
        # Input output settings
        "io": {
            # Names of the parameters
            # format: list of strings
            "parameter_names": ["x1", "x2"]
            # Shape per variable and per file.
            "shapes": {"0": [[1]]},
            # File format
            # format: "npz", "fmt_tp_fortran" (BATMAN) or all Antares formats
            # if installed
            "format": "fmt_tp_fortran",
            # Names of the variables contained in a snapshot
            # format: list of strings
            "variables": ["F"],
            # Name of the file that contains the coordinates of a point in the
            # parameter space
            # format: string
            "point_filename": "header.py",
            # Dictionary of list, if several filenames, several independant
            # analysis are done. It contains the output variables of a
            # snapshot to use by BATMAN,
            # format: list of strings
            "filenames": {"0": ["function.dat"]},
            # Used to restart from existing jobs not created with BATMAN
            "template_directory": "output/snapshots/0/batman-data/header.py",
        },
        # Snapshot provider
        # can also be a python function by setting a python function path
        "provider": {
            # Command to use to launch the script
            # format: string
            "command": "bash",
            # Timeout of each jobs in seconds
            # format: integer
            "timeout": 50,
            # Directiory where the data for the BATMAN computations are stored
            # format: string
            "context": "data",
            # Path of the script or batch to run
            # format: string
            "script": "data/script.sh",
            # Delete after run all except what is inside private-directory
            # format: boolean
            "clean": false,
            # Folder containing the ``point_filename`` and the result of the snapshot
            # format: string
            "private-directory": "batman-data",
            # Output folder to store the ``filenames``
            # format string
            "data-directory": "cfd-output-data",
            # Restart the computation if the job has failed
            "restart": "False"
        }
    },
    #
    # PARAMETERS FOR SURROGATE
    #
    "surrogate": {
        # Set of points at which the predictions are made
        # format: list of tuples of floats
        "predictions": [[1.0, 2.0], [2.0, 1.1]],
        # Method used to generate a snapshot
        # format: one of 'rbf' or 'kriging'
        "method": "kriging"
    },
    #
    # PARAMETERS FOR UNCERTAINTY QUANTIFICATION
    #
    "uq": {
        # Use a test method for indices comparison and quality calculation
        # format: one of 'Rosenbrock', 'Michalewicz', 'Ishigami', 'G_Function',
        # 'Channel_Flow'
        "test": "Michalewicz",
        # Number of points per sample to use for SA
        # format: integer > 0
        "sample": 1000,
        # Enter the PDF of the inputs: x1: Normal(mu, sigma), x2: Uniform(inf,
        # sup)
        "pdf": ["Uniform(1., 3.1415)", "Uniform(1., 3.1415)"],
        # Typy of indices we are interested in
        # format: one of 'aggregated' or 'block'
        "type": "aggregated",
        # Method used for Sobol analysis
        # format: one of 'sobol' or 'FAST'
        "method": "sobol"
    }
}
